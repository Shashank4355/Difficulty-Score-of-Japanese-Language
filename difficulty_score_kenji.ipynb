{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3102a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import MeCab\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ac3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_kanji(char):\n",
    "   \n",
    "    return 'CJK UNIFIED' in unicodedata.name(char)\n",
    "def load_data():\n",
    "    data= pd.read_csv(\"Kanji_char (1).csv\")\n",
    "    df = data.set_index('new')['strokes'].to_dict()\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def calculate_difficulty_score(japanese_text):\n",
    "    # Tokenizing the Japanese text\n",
    "    tokenized_words = tokenize_japanese_text(japanese_text)\n",
    "\n",
    "    #Loading csv file of Kanji character with strokes mentioned and converting it into python dictionary for key-value pair\n",
    "    kanji_strokes_data = load_data()\n",
    "\n",
    "    #threshold for the top 5% of strokes\n",
    "    top_5_percent_threshold = calculate_top_percent_threshold(kanji_strokes_data, 5)\n",
    "\n",
    "    difficulty_score = 0 #initial score\n",
    "    counter =0\n",
    "\n",
    "    for word in tokenized_words:\n",
    "        for char in word:\n",
    "            if is_kanji(char):\n",
    "                counter+=1\n",
    "                strokes = get_number_of_strokes(char, kanji_strokes_data)\n",
    "\n",
    "                if strokes > top_5_percent_threshold:\n",
    "                    difficulty_score += 1\n",
    "    print(\"kanji Character count:\" , counter)\n",
    "\n",
    "    return difficulty_score\n",
    "\n",
    "def tokenize_japanese_text(text):\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokenized_words = mecab.parse(text).split()\n",
    "    return tokenized_words\n",
    "\n",
    "def calculate_top_percent_threshold(strokes_data, top_percent):\n",
    "    all_strokes = list(strokes_data.values())\n",
    "    all_strokes.sort(reverse=True)\n",
    "    threshold_index = int(len(all_strokes) * (top_percent / 100.0))\n",
    "    top_percent_threshold = all_strokes[threshold_index]\n",
    "    return top_percent_threshold\n",
    "\n",
    "def get_number_of_strokes(kanji_char, strokes_data):\n",
    "    return strokes_data.get(kanji_char, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a76aaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kanji Character count: 59\n",
      "Difficulty Score: 1\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path\n",
    "file_path = 'testCases.txt'\n",
    "\n",
    "# Open the file with the appropriate encoding (UTF-8)\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # Read the content of the file\n",
    "    japanese_text = file.read()\n",
    "\n",
    "# Example usage\n",
    "# kanji_text = \"新しい言葉や難解な漢字を学ぶことは言語学習の一部です。\"\n",
    "# kanji_text2 = \"よし子さんは、二月二十日から一 週しゅう間かん、北ほっ海かい道どうに行きました。一日目は、つかれて何なにもできませんでしたが、二日目からは、スキーをしたり、温おんせんに入はいったり、カラオケに行いったりして、とても楽たのしかったです。来らい年ねんの冬ふゆは、スノーボードを習ならいたいです。\"\n",
    "# kanji_text3 = \"こんにちは。お元気ですか。夏休みは何をしていますか。私はこの前、オリンピックを見に行きました。すごく良よかったです！\"\n",
    "# kanji_text4 =\"毎日新聞社が発行する週刊点字新聞「点字毎日」は2022年、創刊100年を迎えた。\"\n",
    "# kanji_text5 = \"新聞の文化的使命を徹底せしめんとするにほかありません。かくして、一方には盲人に対し、一個の独立せる市民として社会に活動するに必要な知識と勇気と慰安とを与え、他方には、これまで盲人に対して眠れる社会の良心を呼び覚まさんとするにあります」と、その理念を格調高くうたい上げている。\"\n",
    "difficulty_score = calculate_difficulty_score(japanese_text)\n",
    "\n",
    "print(\"Difficulty Score:\", difficulty_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2708ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_family = \"Noto Sans JP\"\n",
    "plt.rcParams[\"font.family\"] = font_family\n",
    "\n",
    "def plot_strokes_distribution(strokes_data):\n",
    "    plt.bar(strokes_data.keys(), strokes_data.values())\n",
    "    plt.xlabel('Kanji Characters')\n",
    "    plt.ylabel('Number of Strokes')\n",
    "    plt.title('Strokes Distribution in Kanji Characters')\n",
    "    plt.show()\n",
    "\n",
    "def plot_difficulty_pie_chart(difficulty_stats):\n",
    "    labels = ['Difficult Words', 'Easy Words']\n",
    "    sizes = [difficulty_stats['difficult'], difficulty_stats['easy']]\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Difficulty Distribution in Japanese Text')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ddd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38115244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
